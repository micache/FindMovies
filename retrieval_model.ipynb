{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\App\\anaconda\\envs\\toolkit\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movies data\n",
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
    "#ratings data\n",
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = tfds.as_dataframe(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_genres</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4]</td>\n",
       "      <td>b'1681'</td>\n",
       "      <td>b'You So Crazy (1994)'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4, 7]</td>\n",
       "      <td>b'1457'</td>\n",
       "      <td>b'Love Is All There Is (1996)'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>b'500'</td>\n",
       "      <td>b'Fly Away Home (1996)'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  movie_genres movie_id                     movie_title\n",
       "0          [4]  b'1681'          b'You So Crazy (1994)'\n",
       "1       [4, 7]  b'1457'  b'Love Is All There Is (1996)'\n",
       "2       [1, 3]   b'500'         b'Fly Away Home (1996)'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df = tfds.as_dataframe(movies)\n",
    "for x in movies_df[:3].iterrows():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_ratings(ds):\n",
    "    timestamps = []\n",
    "    features_list = []\n",
    "\n",
    "    for example in ds:\n",
    "        timestamps.append(example['timestamp'])\n",
    "        features_list.append(example)\n",
    "\n",
    "    # convert list to tensor\n",
    "    timestamps = tf.convert_to_tensor(timestamps)\n",
    "    features_list = tf.stack(features_list)\n",
    "    # sort index\n",
    "    sorted_indices = tf.argsort(timestamps)\n",
    "    # sort all data\n",
    "    sorted_features = tf.gather(ds, sorted_indices)\n",
    "    return tf.data.Dataset.from_tensor_slices(sorted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "})\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = movies.batch(2_000)\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'1', b'10', b'100', b'101', b'102', b'103', b'104', b'105',\n",
       "       b'106', b'107'], dtype=object)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_movie_titles = np.unique(list(movie_titles))\n",
    "unique_user_ids = np.unique(list(user_ids))\n",
    "\n",
    "unique_user_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 32\n",
    "\n",
    "user_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_user_ids, mask_token=None),\n",
    "    tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=unique_movie_titles, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "  candidates=movies.batch(128).map(movie_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = tfrs.tasks.Retrieval(\n",
    "  metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Text\n",
    "\n",
    "class MovielensModel(tfrs.Model):\n",
    "\n",
    "  def __init__(self, user_model, movie_model):\n",
    "    super().__init__()\n",
    "    self.movie_model: tf.keras.Model = movie_model\n",
    "    self.user_model: tf.keras.Model = user_model\n",
    "    self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False):\n",
    "    # pick out the user features and pass them into the user model.\n",
    "    user_embeddings = self.user_model(features[\"user_id\"])\n",
    "    # and pick out the movie features and pass them into the movie model,\n",
    "    # getting embeddings back.\n",
    "    positive_movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "\n",
    "    # computes the loss and the metrics.\n",
    "    return self.task(user_embeddings, positive_movie_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovielensModel(user_model, movie_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 6s 399ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0093 - factorized_top_k/top_10_categorical_accuracy: 0.0203 - factorized_top_k/top_50_categorical_accuracy: 0.1000 - factorized_top_k/top_100_categorical_accuracy: 0.1785 - loss: 69866.8345 - regularization_loss: 0.0000e+00 - total_loss: 69866.8345\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 4s 393ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0032 - factorized_top_k/top_5_categorical_accuracy: 0.0206 - factorized_top_k/top_10_categorical_accuracy: 0.0400 - factorized_top_k/top_50_categorical_accuracy: 0.1703 - factorized_top_k/top_100_categorical_accuracy: 0.2924 - loss: 67492.0085 - regularization_loss: 0.0000e+00 - total_loss: 67492.0085\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 4s 388ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0035 - factorized_top_k/top_5_categorical_accuracy: 0.0241 - factorized_top_k/top_10_categorical_accuracy: 0.0463 - factorized_top_k/top_50_categorical_accuracy: 0.1896 - factorized_top_k/top_100_categorical_accuracy: 0.3151 - loss: 66288.0632 - regularization_loss: 0.0000e+00 - total_loss: 66288.0632\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 4s 384ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0038 - factorized_top_k/top_5_categorical_accuracy: 0.0261 - factorized_top_k/top_10_categorical_accuracy: 0.0509 - factorized_top_k/top_50_categorical_accuracy: 0.2032 - factorized_top_k/top_100_categorical_accuracy: 0.3344 - loss: 65589.8821 - regularization_loss: 0.0000e+00 - total_loss: 65589.8821\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 4s 400ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0040 - factorized_top_k/top_5_categorical_accuracy: 0.0282 - factorized_top_k/top_10_categorical_accuracy: 0.0551 - factorized_top_k/top_50_categorical_accuracy: 0.2156 - factorized_top_k/top_100_categorical_accuracy: 0.3496 - loss: 65091.3196 - regularization_loss: 0.0000e+00 - total_loss: 65091.3196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x16923c487d0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 154ms/step - factorized_top_k/top_1_categorical_accuracy: 5.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0055 - factorized_top_k/top_10_categorical_accuracy: 0.0147 - factorized_top_k/top_50_categorical_accuracy: 0.1061 - factorized_top_k/top_100_categorical_accuracy: 0.2182 - loss: 31184.7298 - regularization_loss: 0.0000e+00 - total_loss: 31184.7298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.0005000000237487257,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.005549999885261059,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.014650000259280205,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.10610000044107437,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.21819999814033508,\n",
       " 'loss': 28321.052734375,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 28321.052734375}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'embedding/embeddings:0' shape=(944, 32) dtype=float32, numpy=\n",
       " array([[ 3.55528332e-02,  2.19892971e-02, -9.03975964e-03, ...,\n",
       "          1.40443705e-02,  2.37191208e-02,  1.78357475e-02],\n",
       "        [ 7.29114711e-01, -1.92525759e-01, -1.95666432e-01, ...,\n",
       "          1.25993431e-01, -9.01168063e-02,  3.27466100e-01],\n",
       "        [-3.74643743e-01,  6.77619427e-02,  3.46409798e-01, ...,\n",
       "         -2.00624019e-01,  3.63519825e-02, -5.65037429e-01],\n",
       "        ...,\n",
       "        [-8.34141672e-03,  3.46097916e-01,  6.23958468e-01, ...,\n",
       "         -8.55518281e-01,  4.19525087e-01, -3.38960409e-01],\n",
       "        [ 6.89618140e-02,  4.14748222e-01,  4.39767241e-02, ...,\n",
       "         -4.08544362e-01,  8.06384720e-04, -2.01640323e-01],\n",
       "        [-5.25799751e-01, -2.75419295e-01,  1.01322383e-01, ...,\n",
       "          2.14048401e-01, -3.26329619e-01,  4.70659018e-01]], dtype=float32)>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.user_model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 13: [b'Believers, The (1987)' b'Hellraiser: Bloodline (1996)'\n",
      " b'Screamers (1995)']\n"
     ]
    }
   ],
   "source": [
    "# create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "# recommends movies out of the entire movies dataset.\n",
    "index.index_from_dataset(\n",
    "  movies.batch(128).map(lambda title: (title, model.movie_model(title)))\n",
    ")\n",
    "\n",
    "# get recommendations.\n",
    "_, titles = index(np.array([\"21\"]), k=3)\n",
    "print(f\"Recommendations for user 13: {titles[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toolkit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
