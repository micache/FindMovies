{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = tfds.load('movielens/100k-ratings', split=\"train\")\n",
    "movies = tfds.load('movielens/100k-movies', split=\"train\")\n",
    "\n",
    "# select the basic features.\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"user_rating\": x[\"user_rating\"],\n",
    "})\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffle data and split between train and test.\n",
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "movie_titles = movies.batch(1_000)\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 32\n",
    "\n",
    "user_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=unique_user_ids, mask_token=None),\n",
    "  # We add 1 to account for the unknown token.\n",
    "  tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "])\n",
    "\n",
    "movie_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=unique_movie_titles, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.tasks.ranking.Ranking at 0x247124c47d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfrs.tasks.Ranking(\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.tasks.retrieval.Retrieval at 0x247124b79d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfrs.tasks.Retrieval(\n",
    "    metrics=tfrs.metrics.FactorizedTopK(\n",
    "        candidates=movies.batch(128)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self, rating_weight: float, retrieval_weight: float) -> None:\n",
    "    # We take the loss weights in the constructor: this allows us to instantiate\n",
    "    # several model objects with different loss weights.\n",
    "\n",
    "    super().__init__()\n",
    "\n",
    "    embedding_dimension = 32\n",
    "\n",
    "    # User and movie models.\n",
    "    self.movie_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_movie_titles, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "    ])\n",
    "    self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_user_ids, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # A small model to take in user and movie embeddings and predict ratings.\n",
    "    # We can make this as complicated as we want as long as we output a scalar\n",
    "    # as our prediction.\n",
    "    self.rating_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ])\n",
    "\n",
    "    # The tasks.\n",
    "    self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "    )\n",
    "    self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "        metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=movies.batch(128).map(self.movie_model)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # The loss weights.\n",
    "    self.rating_weight = rating_weight\n",
    "    self.retrieval_weight = retrieval_weight\n",
    "\n",
    "  def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "    # We pick out the user features and pass them into the user model.\n",
    "    user_embeddings = self.user_model(features[\"user_id\"])\n",
    "    # And pick out the movie features and pass them into the movie model.\n",
    "    movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "\n",
    "    return (\n",
    "        user_embeddings,\n",
    "        movie_embeddings,\n",
    "        # We apply the multi-layered rating model to a concatentation of\n",
    "        # user and movie embeddings.\n",
    "        self.rating_model(\n",
    "            tf.concat([user_embeddings, movie_embeddings], axis=1)\n",
    "        ),\n",
    "    )\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "\n",
    "    ratings = features.pop(\"user_rating\")\n",
    "\n",
    "    user_embeddings, movie_embeddings, rating_predictions = self(features)\n",
    "\n",
    "    # We compute the loss for each task.\n",
    "    rating_loss = self.rating_task(\n",
    "        labels=ratings,\n",
    "        predictions=rating_predictions,\n",
    "    )\n",
    "    retrieval_loss = self.retrieval_task(user_embeddings, movie_embeddings)\n",
    "\n",
    "    # And combine them using the loss weights.\n",
    "    return (self.rating_weight * rating_loss\n",
    "            + self.retrieval_weight * retrieval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovielensModel(rating_weight=0.3, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 5s 381ms/step - root_mean_squared_error: 2.0154 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0106 - factorized_top_k/top_10_categorical_accuracy: 0.0217 - factorized_top_k/top_50_categorical_accuracy: 0.1004 - factorized_top_k/top_100_categorical_accuracy: 0.1773 - loss: 69863.5930 - regularization_loss: 0.0000e+00 - total_loss: 69863.5930\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 4s 381ms/step - root_mean_squared_error: 1.1565 - factorized_top_k/top_1_categorical_accuracy: 0.0027 - factorized_top_k/top_5_categorical_accuracy: 0.0194 - factorized_top_k/top_10_categorical_accuracy: 0.0382 - factorized_top_k/top_50_categorical_accuracy: 0.1670 - factorized_top_k/top_100_categorical_accuracy: 0.2897 - loss: 67501.9474 - regularization_loss: 0.0000e+00 - total_loss: 67501.9474\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 4s 383ms/step - root_mean_squared_error: 1.1650 - factorized_top_k/top_1_categorical_accuracy: 0.0031 - factorized_top_k/top_5_categorical_accuracy: 0.0223 - factorized_top_k/top_10_categorical_accuracy: 0.0446 - factorized_top_k/top_50_categorical_accuracy: 0.1863 - factorized_top_k/top_100_categorical_accuracy: 0.3126 - loss: 66309.9659 - regularization_loss: 0.0000e+00 - total_loss: 66309.9659\n",
      "5/5 [==============================] - 1s 149ms/step - root_mean_squared_error: 1.0756 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0094 - factorized_top_k/top_10_categorical_accuracy: 0.0214 - factorized_top_k/top_50_categorical_accuracy: 0.1234 - factorized_top_k/top_100_categorical_accuracy: 0.2303 - loss: 31090.4827 - regularization_loss: 0.0000e+00 - total_loss: 31090.4827\n",
      "Retrieval top-100 accuracy: 0.230.\n",
      "Ranking RMSE: 1.076.\n"
     ]
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_movie_embeddings, trained_user_embeddings, predicted_rating = model({\n",
    "      \"user_id\": np.array([\"42\"]),\n",
    "      \"movie_title\": np.array([\"Dances with Wolves (1990)\"])\n",
    "  })\n",
    "print(\"Predicted rating:\")\n",
    "print(predicted_rating)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toolkit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
